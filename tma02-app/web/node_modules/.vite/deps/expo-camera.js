import {
  CodedError,
  PermissionStatus,
  Platform_default,
  UnavailabilityError,
  createPermissionHook,
  require_browser
} from "./chunk-A6OG7HSN.js";
import {
  StyleSheet_default,
  View_default,
  createElement_default,
  findNodeHandle_default
} from "./chunk-ZGUEPV2B.js";
import "./chunk-PZ5AM5BG.js";
import {
  __publicField,
  __toESM,
  require_react
} from "./chunk-QG5CKJVI.js";

// ../node_modules/expo-camera/build/Camera.js
var React4 = __toESM(require_react());

// ../node_modules/expo-camera/build/ExponentCamera.web.js
var React3 = __toESM(require_react());

// ../node_modules/expo-camera/build/Camera.types.js
var CameraType;
(function(CameraType2) {
  CameraType2["front"] = "front";
  CameraType2["back"] = "back";
})(CameraType || (CameraType = {}));
var FlashMode;
(function(FlashMode2) {
  FlashMode2["on"] = "on";
  FlashMode2["off"] = "off";
  FlashMode2["auto"] = "auto";
  FlashMode2["torch"] = "torch";
})(FlashMode || (FlashMode = {}));
var AutoFocus;
(function(AutoFocus2) {
  AutoFocus2["on"] = "on";
  AutoFocus2["off"] = "off";
  AutoFocus2["auto"] = "auto";
  AutoFocus2["singleShot"] = "singleShot";
})(AutoFocus || (AutoFocus = {}));
var WhiteBalance;
(function(WhiteBalance2) {
  WhiteBalance2["auto"] = "auto";
  WhiteBalance2["sunny"] = "sunny";
  WhiteBalance2["cloudy"] = "cloudy";
  WhiteBalance2["shadow"] = "shadow";
  WhiteBalance2["incandescent"] = "incandescent";
  WhiteBalance2["fluorescent"] = "fluorescent";
  WhiteBalance2["continuous"] = "continuous";
  WhiteBalance2["manual"] = "manual";
})(WhiteBalance || (WhiteBalance = {}));
var ImageType;
(function(ImageType2) {
  ImageType2["png"] = "png";
  ImageType2["jpg"] = "jpg";
})(ImageType || (ImageType = {}));
var VideoCodec;
(function(VideoCodec2) {
  VideoCodec2["H264"] = "avc1";
  VideoCodec2["HEVC"] = "hvc1";
  VideoCodec2["JPEG"] = "jpeg";
  VideoCodec2["AppleProRes422"] = "apcn";
  VideoCodec2["AppleProRes4444"] = "ap4h";
})(VideoCodec || (VideoCodec = {}));
var VideoStabilization;
(function(VideoStabilization2) {
  VideoStabilization2["off"] = "off";
  VideoStabilization2["standard"] = "standard";
  VideoStabilization2["cinematic"] = "cinematic";
  VideoStabilization2["auto"] = "auto";
})(VideoStabilization || (VideoStabilization = {}));
var VideoQuality;
(function(VideoQuality2) {
  VideoQuality2["2160p"] = "2160p";
  VideoQuality2["1080p"] = "1080p";
  VideoQuality2["720p"] = "720p";
  VideoQuality2["480p"] = "480p";
  VideoQuality2["4:3"] = "4:3";
})(VideoQuality || (VideoQuality = {}));
var CameraOrientation;
(function(CameraOrientation2) {
  CameraOrientation2[CameraOrientation2["portrait"] = 1] = "portrait";
  CameraOrientation2[CameraOrientation2["portraitUpsideDown"] = 2] = "portraitUpsideDown";
  CameraOrientation2[CameraOrientation2["landscapeLeft"] = 3] = "landscapeLeft";
  CameraOrientation2[CameraOrientation2["landscapeRight"] = 4] = "landscapeRight";
})(CameraOrientation || (CameraOrientation = {}));

// ../node_modules/expo-camera/build/WebUserMediaManager.js
async function requestLegacyUserMediaAsync(props) {
  const optionalSource = (id) => ({ optional: [{ sourceId: id }] });
  const constraintToSourceId = (constraint) => {
    const { deviceId } = constraint;
    if (typeof deviceId === "string") {
      return deviceId;
    }
    if (Array.isArray(deviceId) && deviceId.length > 0) {
      return deviceId[0];
    }
    if (typeof deviceId === "object" && deviceId.ideal) {
      return deviceId.ideal;
    }
    return null;
  };
  const sources = await new Promise((resolve) => (
    // @ts-ignore: https://caniuse.com/#search=getSources Chrome for Android (78) & Samsung Internet (10.1) use this
    MediaStreamTrack.getSources((sources2) => resolve(sources2))
  ));
  let audioSource = null;
  let videoSource = null;
  sources.forEach((source) => {
    if (source.kind === "audio") {
      audioSource = source.id;
    } else if (source.kind === "video") {
      videoSource = source.id;
    }
  });
  const audioSourceId = constraintToSourceId(props.audioConstraints);
  if (audioSourceId) {
    audioSource = audioSourceId;
  }
  const videoSourceId = constraintToSourceId(props.videoConstraints);
  if (videoSourceId) {
    videoSource = videoSourceId;
  }
  return [optionalSource(audioSource), optionalSource(videoSource)];
}
async function sourceSelectedAsync(isMuted, audioConstraints, videoConstraints) {
  const constraints = {
    video: typeof videoConstraints !== "undefined" ? videoConstraints : true
  };
  if (!isMuted) {
    constraints.audio = typeof audioConstraints !== "undefined" ? audioConstraints : true;
  }
  return await getAnyUserMediaAsync(constraints);
}
async function requestUserMediaAsync(props, isMuted = true) {
  if (canGetUserMedia()) {
    return await sourceSelectedAsync(isMuted, props.audio, props.video);
  }
  const [audio, video] = await requestLegacyUserMediaAsync(props);
  return await sourceSelectedAsync(isMuted, audio, video);
}
async function getAnyUserMediaAsync(constraints, ignoreConstraints = false) {
  try {
    return await getUserMediaAsync({
      ...constraints,
      video: ignoreConstraints || constraints.video
    });
  } catch (error) {
    if (!ignoreConstraints && error.name === "ConstraintNotSatisfiedError") {
      return await getAnyUserMediaAsync(constraints, true);
    }
    throw error;
  }
}
async function getUserMediaAsync(constraints) {
  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    return navigator.mediaDevices.getUserMedia(constraints);
  }
  const _getUserMedia = navigator["mozGetUserMedia"] || navigator["webkitGetUserMedia"] || navigator["msGetUserMedia"];
  return new Promise((resolve, reject) => _getUserMedia.call(navigator, constraints, resolve, reject));
}
function canGetUserMedia() {
  return (
    // SSR
    Platform_default.isDOMAvailable && // Has any form of media API
    !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia || navigator["mozGetUserMedia"] || navigator["webkitGetUserMedia"] || navigator["msGetUserMedia"])
  );
}
async function isFrontCameraAvailableAsync(devices) {
  return await supportsCameraType(["front", "user", "facetime"], "user", devices);
}
async function isBackCameraAvailableAsync(devices) {
  return await supportsCameraType(["back", "rear"], "environment", devices);
}
async function supportsCameraType(labels, type, devices) {
  if (!devices) {
    if (!navigator.mediaDevices.enumerateDevices) {
      return null;
    }
    devices = await navigator.mediaDevices.enumerateDevices();
  }
  const cameras = devices.filter((t) => t.kind === "videoinput");
  const [hasCamera] = cameras.filter((camera) => labels.some((label) => camera.label.toLowerCase().includes(label)));
  const [isCapable] = cameras.filter((camera) => {
    if (!("getCapabilities" in camera)) {
      return null;
    }
    const capabilities = camera.getCapabilities();
    if (!capabilities.facingMode) {
      return null;
    }
    return capabilities.facingMode.find((_) => type);
  });
  return (isCapable == null ? void 0 : isCapable.deviceId) || (hasCamera == null ? void 0 : hasCamera.deviceId) || null;
}

// ../node_modules/expo-camera/build/ExponentCameraManager.web.js
function getUserMedia(constraints) {
  if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
    return navigator.mediaDevices.getUserMedia(constraints);
  }
  const getUserMedia2 = (
    // TODO: this method is deprecated, migrate to https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia
    navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || function() {
      const error = new Error("Permission unimplemented");
      error.code = 0;
      error.name = "NotAllowedError";
      throw error;
    }
  );
  return new Promise((resolve, reject) => {
    getUserMedia2.call(navigator, constraints, resolve, reject);
  });
}
function handleGetUserMediaError({ message }) {
  if (message === "Permission dismissed") {
    return {
      status: PermissionStatus.UNDETERMINED,
      expires: "never",
      canAskAgain: true,
      granted: false
    };
  } else {
    return {
      status: PermissionStatus.DENIED,
      expires: "never",
      canAskAgain: true,
      granted: false
    };
  }
}
async function handleRequestPermissionsAsync() {
  try {
    await getUserMedia({
      video: true
    });
    return {
      status: PermissionStatus.GRANTED,
      expires: "never",
      canAskAgain: true,
      granted: true
    };
  } catch ({ message }) {
    return handleGetUserMediaError({ message });
  }
}
async function handlePermissionsQueryAsync(query) {
  var _a;
  if (!((_a = navigator == null ? void 0 : navigator.permissions) == null ? void 0 : _a.query)) {
    throw new UnavailabilityError("expo-camera", "navigator.permissions API is not available");
  }
  const { state } = await navigator.permissions.query({ name: query });
  switch (state) {
    case "prompt":
      return {
        status: PermissionStatus.UNDETERMINED,
        expires: "never",
        canAskAgain: true,
        granted: false
      };
    case "granted":
      return {
        status: PermissionStatus.GRANTED,
        expires: "never",
        canAskAgain: true,
        granted: true
      };
    case "denied":
      return {
        status: PermissionStatus.DENIED,
        expires: "never",
        canAskAgain: true,
        granted: false
      };
  }
}
var ExponentCameraManager_web_default = {
  get name() {
    return "ExponentCameraManager";
  },
  get Type() {
    return {
      back: "back",
      front: "front"
    };
  },
  get FlashMode() {
    return {
      on: "on",
      off: "off",
      auto: "auto",
      torch: "torch"
    };
  },
  get AutoFocus() {
    return {
      on: "on",
      off: "off",
      auto: "auto",
      singleShot: "singleShot"
    };
  },
  get WhiteBalance() {
    return {
      auto: "auto",
      continuous: "continuous",
      manual: "manual"
    };
  },
  get VideoQuality() {
    return {};
  },
  get VideoStabilization() {
    return {};
  },
  async isAvailableAsync() {
    return canGetUserMedia();
  },
  async takePicture(options, camera) {
    return await camera.takePicture(options);
  },
  async pausePreview(camera) {
    await camera.pausePreview();
  },
  async resumePreview(camera) {
    return await camera.resumePreview();
  },
  async getAvailableCameraTypesAsync() {
    if (!canGetUserMedia() || !navigator.mediaDevices.enumerateDevices)
      return [];
    const devices = await navigator.mediaDevices.enumerateDevices();
    const types = await Promise.all([
      await isFrontCameraAvailableAsync(devices) && CameraType.front,
      await isBackCameraAvailableAsync() && CameraType.back
    ]);
    return types.filter(Boolean);
  },
  async getAvailablePictureSizes(ratio, camera) {
    return await camera.getAvailablePictureSizes(ratio);
  },
  /* async getSupportedRatios(camera: ExponentCameraRef): Promise<string[]> {
    // TODO: Support on web
  },
  async record(
    options?: CameraRecordingOptions,
    camera: ExponentCameraRef
  ): Promise<{ uri: string }> {
    // TODO: Support on web
  },
  async stopRecording(camera: ExponentCameraRef): Promise<void> {
    // TODO: Support on web
  }, */
  async getPermissionsAsync() {
    return handlePermissionsQueryAsync("camera");
  },
  async requestPermissionsAsync() {
    return handleRequestPermissionsAsync();
  },
  async getCameraPermissionsAsync() {
    return handlePermissionsQueryAsync("camera");
  },
  async requestCameraPermissionsAsync() {
    return handleRequestPermissionsAsync();
  },
  async getMicrophonePermissionsAsync() {
    return handlePermissionsQueryAsync("microphone");
  },
  async requestMicrophonePermissionsAsync() {
    try {
      await getUserMedia({
        audio: true
      });
      return {
        status: PermissionStatus.GRANTED,
        expires: "never",
        canAskAgain: true,
        granted: true
      };
    } catch ({ message }) {
      return handleGetUserMediaError({ message });
    }
  }
};

// ../node_modules/expo-camera/build/WebCameraUtils.js
var import_invariant = __toESM(require_browser());

// ../node_modules/expo-camera/build/WebCapabilityUtils.js
function convertFlashModeJSONToNative(input) {
  switch (input) {
    case "torch":
      return true;
    case "on":
    case "off":
    case "auto":
    default:
      return false;
  }
}
function convertWhiteBalanceJSONToNative(input) {
  switch (input) {
    case "on":
    case "auto":
      return "continuous";
    case "off":
      return "none";
    case "singleShot":
      return "single-shot";
    default:
      return void 0;
  }
}
function convertAutoFocusJSONToNative(input) {
  switch (input) {
    case "on":
    case "auto":
      return "continuous";
    case "off":
      return "manual";
    case "singleShot":
      return "single-shot";
    default:
      return void 0;
  }
}

// ../node_modules/expo-camera/build/WebConstants.js
var VIDEO_ASPECT_RATIOS = {
  "3840x2160": 3840 / 2160,
  "1920x1080": 1920 / 1080,
  "1280x720": 1280 / 720,
  "640x480": 640 / 480,
  "352x288": 352 / 288
};
var PictureSizes = Object.keys(VIDEO_ASPECT_RATIOS);
var ImageTypeFormat = {
  [ImageType.jpg]: "image/jpeg",
  [ImageType.png]: "image/png"
};
var MinimumConstraints = {
  audio: false,
  video: true
};
var CameraTypeToFacingMode = {
  [CameraType.front]: "user",
  [CameraType.back]: "environment"
};
var FacingModeToCameraType = {
  user: CameraType.front,
  environment: CameraType.back
};

// ../node_modules/expo-camera/build/WebCameraUtils.js
function getImageSize(videoWidth, videoHeight, scale) {
  const width = videoWidth * scale;
  const ratio = videoWidth / width;
  const height = videoHeight / ratio;
  return {
    width,
    height
  };
}
function toDataURL(canvas, imageType, quality) {
  (0, import_invariant.default)(Object.values(ImageType).includes(imageType), `expo-camera: ${imageType} is not a valid ImageType. Expected a string from: ${Object.values(ImageType).join(", ")}`);
  const format = ImageTypeFormat[imageType];
  if (imageType === ImageType.jpg) {
    (0, import_invariant.default)(quality <= 1 && quality >= 0, `expo-camera: ${quality} is not a valid image quality. Expected a number from 0...1`);
    return canvas.toDataURL(format, quality);
  } else {
    return canvas.toDataURL(format);
  }
}
function hasValidConstraints(preferredCameraType, width, height) {
  return preferredCameraType !== void 0 && width !== void 0 && height !== void 0;
}
function ensureCameraPictureOptions(config) {
  const captureOptions = {
    scale: 1,
    imageType: ImageType.png,
    isImageMirror: false
  };
  for (const key in config) {
    if (key in config && config[key] !== void 0 && key in captureOptions) {
      captureOptions[key] = config[key];
    }
  }
  return captureOptions;
}
var DEFAULT_QUALITY = 0.92;
function captureImageData(video, pictureOptions = {}) {
  if (!video || video.readyState !== video.HAVE_ENOUGH_DATA) {
    return null;
  }
  const canvas = captureImageContext(video, pictureOptions);
  const context = canvas.getContext("2d", { alpha: false });
  if (!context || !canvas.width || !canvas.height) {
    return null;
  }
  const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
  return imageData;
}
function captureImageContext(video, { scale = 1, isImageMirror = false }) {
  const { videoWidth, videoHeight } = video;
  const { width, height } = getImageSize(videoWidth, videoHeight, scale);
  const canvas = document.createElement("canvas");
  canvas.width = width;
  canvas.height = height;
  const context = canvas.getContext("2d", { alpha: false });
  if (!context) {
    throw new Error("Context is not defined");
  }
  if (isImageMirror) {
    context.setTransform(-1, 0, 0, 1, canvas.width, 0);
  }
  context.drawImage(video, 0, 0, width, height);
  return canvas;
}
function captureImage(video, pictureOptions) {
  const config = ensureCameraPictureOptions(pictureOptions);
  const canvas = captureImageContext(video, config);
  const { imageType, quality = DEFAULT_QUALITY } = config;
  return toDataURL(canvas, imageType, quality);
}
function getSupportedConstraints() {
  if (navigator.mediaDevices && navigator.mediaDevices.getSupportedConstraints) {
    return navigator.mediaDevices.getSupportedConstraints();
  }
  return null;
}
function getIdealConstraints(preferredCameraType, width, height) {
  const preferredConstraints = {
    audio: false,
    video: {}
  };
  if (hasValidConstraints(preferredCameraType, width, height)) {
    return MinimumConstraints;
  }
  const supports = getSupportedConstraints();
  if (!supports || !supports.facingMode || !supports.width || !supports.height) {
    return MinimumConstraints;
  }
  if (preferredCameraType && Object.values(CameraType).includes(preferredCameraType)) {
    const facingMode = CameraTypeToFacingMode[preferredCameraType];
    if (isWebKit()) {
      const key = facingMode === "user" ? "exact" : "ideal";
      preferredConstraints.video.facingMode = {
        [key]: facingMode
      };
    } else {
      preferredConstraints.video.facingMode = {
        ideal: CameraTypeToFacingMode[preferredCameraType]
      };
    }
  }
  if (isMediaTrackConstraints(preferredConstraints.video)) {
    preferredConstraints.video.width = width;
    preferredConstraints.video.height = height;
  }
  return preferredConstraints;
}
function isMediaTrackConstraints(input) {
  return input && typeof input.video !== "boolean";
}
async function getPreferredStreamDevice(preferredCameraType, preferredWidth, preferredHeight) {
  try {
    return await getStreamDevice(preferredCameraType, preferredWidth, preferredHeight);
  } catch (error) {
    if (error instanceof OverconstrainedError && error.constraint === "facingMode") {
      const nextCameraType = preferredCameraType === CameraType.back ? CameraType.front : CameraType.back;
      return await getStreamDevice(nextCameraType, preferredWidth, preferredHeight);
    }
    throw error;
  }
}
async function getStreamDevice(preferredCameraType, preferredWidth, preferredHeight) {
  const constraints = getIdealConstraints(preferredCameraType, preferredWidth, preferredHeight);
  const stream = await requestUserMediaAsync(constraints);
  return stream;
}
function isWebKit() {
  return /WebKit/.test(navigator.userAgent) && !/Edg/.test(navigator.userAgent);
}
function compareStreams(a, b) {
  if (!a || !b) {
    return false;
  }
  const settingsA = a.getTracks()[0].getSettings();
  const settingsB = b.getTracks()[0].getSettings();
  return settingsA.deviceId === settingsB.deviceId;
}
function capture(video, settings, config) {
  const base64 = captureImage(video, config);
  const capturedPicture = {
    uri: base64,
    base64,
    width: 0,
    height: 0
  };
  if (settings) {
    const { width = 0, height = 0 } = settings;
    capturedPicture.width = width;
    capturedPicture.height = height;
    capturedPicture.exif = settings;
  }
  if (config.onPictureSaved) {
    config.onPictureSaved(capturedPicture);
  }
  return capturedPicture;
}
async function syncTrackCapabilities(cameraType, stream, settings = {}) {
  if (stream == null ? void 0 : stream.getVideoTracks) {
    await Promise.all(stream.getVideoTracks().map((track) => onCapabilitiesReady(cameraType, track, settings)));
  }
}
async function onCapabilitiesReady(cameraType, track, settings = {}) {
  const capabilities = track.getCapabilities();
  const constraints = {};
  const clampedValues = [
    "exposureCompensation",
    "colorTemperature",
    "iso",
    "brightness",
    "contrast",
    "saturation",
    "sharpness",
    "focusDistance",
    "zoom"
  ];
  for (const property of clampedValues) {
    if (capabilities[property]) {
      constraints[property] = convertNormalizedSetting(capabilities[property], settings[property]);
    }
  }
  function validatedInternalConstrainedValue(constraintKey, settingsKey, converter) {
    const convertedSetting = converter(settings[settingsKey]);
    return validatedConstrainedValue({
      constraintKey,
      settingsKey,
      convertedSetting,
      capabilities,
      settings,
      cameraType
    });
  }
  if (capabilities.focusMode && settings.autoFocus !== void 0) {
    constraints.focusMode = validatedInternalConstrainedValue("focusMode", "autoFocus", convertAutoFocusJSONToNative);
  }
  if (capabilities.torch && settings.flashMode !== void 0) {
    constraints.torch = validatedInternalConstrainedValue("torch", "flashMode", convertFlashModeJSONToNative);
  }
  if (capabilities.whiteBalanceMode && settings.whiteBalance !== void 0) {
    constraints.whiteBalanceMode = validatedInternalConstrainedValue("whiteBalanceMode", "whiteBalance", convertWhiteBalanceJSONToNative);
  }
  try {
    await track.applyConstraints({ advanced: [constraints] });
  } catch (error) {
    if (__DEV__)
      console.warn("Failed to apply constraints", error);
  }
}
function stopMediaStream(stream) {
  if (!stream) {
    return;
  }
  if (stream.getAudioTracks) {
    stream.getAudioTracks().forEach((track) => track.stop());
  }
  if (stream.getVideoTracks) {
    stream.getVideoTracks().forEach((track) => track.stop());
  }
  if (isMediaStreamTrack(stream)) {
    stream.stop();
  }
}
function setVideoSource(video, stream) {
  const createObjectURL = window.URL.createObjectURL ?? window.webkitURL.createObjectURL;
  if (typeof video.srcObject !== "undefined") {
    video.srcObject = stream;
  } else if (typeof video.mozSrcObject !== "undefined") {
    video.mozSrcObject = stream;
  } else if (stream && createObjectURL) {
    video.src = createObjectURL(stream);
  }
  if (!stream) {
    const revokeObjectURL = window.URL.revokeObjectURL ?? window.webkitURL.revokeObjectURL;
    const source = video.src ?? video.srcObject ?? video.mozSrcObject;
    if (revokeObjectURL && typeof source === "string") {
      revokeObjectURL(source);
    }
  }
}
function isMediaStreamTrack(input) {
  return typeof input.stop === "function";
}
function convertNormalizedSetting(range, value) {
  if (!value) {
    return;
  }
  const converted = convertRange(value, [range.min, range.max]);
  return Math.min(range.max, Math.max(range.min, converted));
}
function convertRange(value, r2, r1 = [0, 1]) {
  return (value - r1[0]) * (r2[1] - r2[0]) / (r1[1] - r1[0]) + r2[0];
}
function validatedConstrainedValue(props) {
  const { constraintKey, settingsKey, convertedSetting, capabilities, settings, cameraType } = props;
  const setting = settings[settingsKey];
  if (Array.isArray(capabilities[constraintKey]) && convertedSetting && !capabilities[constraintKey].includes(convertedSetting)) {
    if (__DEV__) {
      console.warn(` { ${settingsKey}: "${setting}" } (converted to "${convertedSetting}" in the browser) is not supported for camera type "${cameraType}" in your browser. Using the default value instead.`);
    }
    return void 0;
  }
  return convertedSetting;
}

// ../node_modules/expo-camera/build/useWebCameraStream.js
var React = __toESM(require_react());
var VALID_SETTINGS_KEYS = [
  "autoFocus",
  "flashMode",
  "exposureCompensation",
  "colorTemperature",
  "iso",
  "brightness",
  "contrast",
  "saturation",
  "sharpness",
  "focusDistance",
  "whiteBalance",
  "zoom"
];
function useLoadedVideo(video, onLoaded) {
  React.useEffect(() => {
    if (video) {
      video.addEventListener("loadedmetadata", () => {
        requestAnimationFrame(() => {
          onLoaded();
        });
      });
    }
  }, [video]);
}
function useWebCameraStream(video, preferredType, settings, { onCameraReady, onMountError }) {
  const isStartingCamera = React.useRef(false);
  const activeStreams = React.useRef([]);
  const capabilities = React.useRef({
    autoFocus: "continuous",
    flashMode: "off",
    whiteBalance: "continuous",
    zoom: 1
  });
  const [stream, setStream] = React.useState(null);
  const mediaTrackSettings = React.useMemo(() => {
    return stream ? stream.getTracks()[0].getSettings() : null;
  }, [stream]);
  const type = React.useMemo(() => {
    if (!mediaTrackSettings) {
      return null;
    }
    const { facingMode = "user" } = mediaTrackSettings;
    return FacingModeToCameraType[facingMode];
  }, [mediaTrackSettings]);
  const getStreamDeviceAsync = React.useCallback(async () => {
    try {
      return await getPreferredStreamDevice(preferredType);
    } catch (nativeEvent) {
      if (__DEV__) {
        console.warn(`Error requesting UserMedia for type "${preferredType}":`, nativeEvent);
      }
      if (onMountError) {
        onMountError({ nativeEvent });
      }
      return null;
    }
  }, [preferredType, onMountError]);
  const resumeAsync = React.useCallback(async () => {
    const nextStream = await getStreamDeviceAsync();
    if (compareStreams(nextStream, stream)) {
      return false;
    }
    if (!activeStreams.current.some((value) => value.id === (nextStream == null ? void 0 : nextStream.id))) {
      activeStreams.current.push(nextStream);
    }
    setStream(nextStream);
    if (onCameraReady) {
      onCameraReady();
    }
    return false;
  }, [getStreamDeviceAsync, setStream, onCameraReady, stream, activeStreams.current]);
  React.useEffect(() => {
    if (isStartingCamera.current) {
      return;
    }
    isStartingCamera.current = true;
    resumeAsync().then((isStarting) => {
      isStartingCamera.current = isStarting;
    }).catch(() => {
      isStartingCamera.current = false;
    });
  }, [preferredType]);
  React.useEffect(() => {
    const changes = {};
    for (const key of Object.keys(settings)) {
      if (!VALID_SETTINGS_KEYS.includes(key)) {
        continue;
      }
      const nextValue = settings[key];
      if (nextValue !== capabilities.current[key]) {
        changes[key] = nextValue;
      }
    }
    const hasChanges = !!Object.keys(changes).length;
    const nextWebCameraSettings = { ...capabilities.current, ...changes };
    if (hasChanges) {
      syncTrackCapabilities(preferredType, stream, changes);
    }
    capabilities.current = nextWebCameraSettings;
  }, [
    settings.autoFocus,
    settings.flashMode,
    settings.exposureCompensation,
    settings.colorTemperature,
    settings.iso,
    settings.brightness,
    settings.contrast,
    settings.saturation,
    settings.sharpness,
    settings.focusDistance,
    settings.whiteBalance,
    settings.zoom
  ]);
  React.useEffect(() => {
    if (!video.current) {
      return;
    }
    setVideoSource(video.current, stream);
  }, [video.current, stream]);
  React.useEffect(() => {
    return () => {
      for (const stream2 of activeStreams.current) {
        stopMediaStream(stream2);
      }
      if (video.current) {
        setVideoSource(video.current, stream);
      }
    };
  }, []);
  useLoadedVideo(video.current, () => {
    syncTrackCapabilities(preferredType, stream, capabilities.current);
  });
  return {
    type,
    mediaTrackSettings
  };
}

// ../node_modules/expo-camera/build/useWebQRScanner.js
var React2 = __toESM(require_react());
var qrWorkerMethod = ({ data, width, height }) => {
  const decoded = self.jsQR(data, width, height, {
    inversionAttempts: "attemptBoth"
  });
  let parsed;
  try {
    parsed = JSON.parse(decoded);
  } catch {
    parsed = decoded;
  }
  if (parsed == null ? void 0 : parsed.data) {
    const nativeEvent = {
      type: "qr",
      data: parsed.data,
      cornerPoints: [],
      bounds: { origin: { x: 0, y: 0 }, size: { width: 0, height: 0 } }
    };
    if (parsed.location) {
      nativeEvent.cornerPoints = [
        parsed.location.topLeftCorner,
        parsed.location.bottomLeftCorner,
        parsed.location.topRightCorner,
        parsed.location.bottomRightCorner
      ];
    }
    return nativeEvent;
  }
  return parsed;
};
var createWorkerAsyncFunction = (fn, deps) => {
  const stringifiedFn = [
    `self.func = ${fn.toString()};`,
    "self.onmessage = (e) => {",
    "  const result = self.func(e.data);",
    "  self.postMessage(result);",
    "};"
  ];
  if (deps.length > 0) {
    stringifiedFn.unshift(`importScripts(${deps.map((dep) => `'${dep}'`).join(", ")});`);
  }
  const blob = new Blob(stringifiedFn, { type: "text/javascript" });
  const worker = new Worker(URL.createObjectURL(blob));
  const promises = [];
  worker.onmessage = (e) => {
    var _a;
    return (_a = promises.shift()) == null ? void 0 : _a.resolve(e.data);
  };
  return (data) => {
    return new Promise((resolve, reject) => {
      promises.push({ resolve, reject });
      worker.postMessage(data);
    });
  };
};
var decode = createWorkerAsyncFunction(qrWorkerMethod, [
  "https://cdn.jsdelivr.net/npm/jsqr@1.2.0/dist/jsQR.min.js"
]);
function useWebQRScanner(video, { isEnabled, captureOptions, interval, onScanned, onError }) {
  const isRunning = React2.useRef(false);
  const timeout = React2.useRef(void 0);
  async function scanAsync() {
    if (!isRunning.current || !onScanned) {
      stop();
      return;
    }
    try {
      const data = captureImageData(video.current, captureOptions);
      if (data) {
        const nativeEvent = await decode(data);
        if (nativeEvent == null ? void 0 : nativeEvent.data) {
          onScanned({
            nativeEvent
          });
        }
      }
    } catch (error) {
      if (onError) {
        onError({ nativeEvent: error });
      }
    } finally {
      if (interval === 0) {
        stop();
        return;
      }
      const intervalToUse = !interval || interval < 0 ? 16 : interval;
      timeout.current = setTimeout(() => {
        scanAsync();
      }, intervalToUse);
    }
  }
  function stop() {
    isRunning.current = false;
    clearTimeout(timeout.current);
  }
  React2.useEffect(() => {
    if (isEnabled) {
      isRunning.current = true;
      scanAsync();
    }
    return () => {
      if (isEnabled) {
        stop();
      }
    };
  }, [isEnabled]);
}

// ../node_modules/expo-camera/build/ExponentCamera.web.js
var ExponentCamera = React3.forwardRef(({ type, pictureSize, poster, ...props }, ref) => {
  var _a, _b;
  const video = React3.useRef(null);
  const native = useWebCameraStream(video, type, props, {
    onCameraReady() {
      if (props.onCameraReady) {
        props.onCameraReady();
      }
    },
    onMountError: props.onMountError
  });
  const isQRScannerEnabled = React3.useMemo(() => {
    var _a2, _b2;
    return !!(((_b2 = (_a2 = props.barCodeScannerSettings) == null ? void 0 : _a2.barCodeTypes) == null ? void 0 : _b2.includes("qr")) && !!props.onBarCodeScanned);
  }, [(_a = props.barCodeScannerSettings) == null ? void 0 : _a.barCodeTypes, props.onBarCodeScanned]);
  useWebQRScanner(video, {
    interval: (_b = props.barCodeScannerSettings) == null ? void 0 : _b.interval,
    isEnabled: isQRScannerEnabled,
    captureOptions: { scale: 1, isImageMirror: native.type === CameraType.front },
    onScanned(event) {
      if (props.onBarCodeScanned) {
        props.onBarCodeScanned(event);
      }
    }
    // onError: props.onMountError,
  });
  React3.useImperativeHandle(ref, () => ({
    async getAvailablePictureSizes(ratio) {
      return PictureSizes;
    },
    async takePicture(options) {
      var _a2, _b2;
      if (!video.current || ((_a2 = video.current) == null ? void 0 : _a2.readyState) !== ((_b2 = video.current) == null ? void 0 : _b2.HAVE_ENOUGH_DATA)) {
        throw new CodedError("ERR_CAMERA_NOT_READY", "HTMLVideoElement does not have enough camera data to construct an image yet.");
      }
      const settings = native.mediaTrackSettings;
      if (!settings) {
        throw new CodedError("ERR_CAMERA_NOT_READY", "MediaStream is not ready yet.");
      }
      return capture(video.current, settings, {
        ...options,
        // This will always be defined, the option gets added to a queue in the upper-level. We should replace the original so it isn't called twice.
        onPictureSaved(picture) {
          if (options.onPictureSaved) {
            options.onPictureSaved(picture);
          }
          if (props.onPictureSaved) {
            props.onPictureSaved({ nativeEvent: { data: picture, id: -1 } });
          }
        }
      });
    },
    async resumePreview() {
      if (video.current) {
        video.current.play();
      }
    },
    async pausePreview() {
      if (video.current) {
        video.current.pause();
      }
    }
  }), [native.mediaTrackSettings, props.onPictureSaved]);
  const isMuted = true;
  const style = React3.useMemo(() => {
    const isFrontFacingCamera = native.type === ExponentCameraManager_web_default.Type.front;
    return [
      StyleSheet_default.absoluteFill,
      styles.video,
      {
        // Flip the camera
        transform: isFrontFacingCamera ? [{ scaleX: -1 }] : void 0
      }
    ];
  }, [native.type]);
  return React3.createElement(
    View_default,
    { pointerEvents: "box-none", style: [styles.videoWrapper, props.style] },
    React3.createElement(Video, {
      autoPlay: true,
      playsInline: true,
      muted: isMuted,
      poster,
      // webkitPlaysinline
      pointerEvents: props.pointerEvents,
      ref: video,
      style
    }),
    props.children
  );
});
var ExponentCamera_web_default = ExponentCamera;
var Video = React3.forwardRef((props, ref) => createElement_default("video", { ...props, ref }));
var styles = StyleSheet_default.create({
  videoWrapper: {
    flex: 1,
    alignItems: "stretch"
  },
  video: {
    width: "100%",
    height: "100%",
    objectFit: "cover"
  }
});

// ../node_modules/expo-camera/build/utils/props.js
var ConversionTables = {
  type: ExponentCameraManager_web_default.Type,
  flashMode: ExponentCameraManager_web_default.FlashMode,
  autoFocus: ExponentCameraManager_web_default.AutoFocus,
  whiteBalance: ExponentCameraManager_web_default.WhiteBalance
};
function convertNativeProps(props) {
  if (!props || typeof props !== "object") {
    return {};
  }
  const nativeProps = {};
  for (const [key, value] of Object.entries(props)) {
    if (typeof value === "string" && ConversionTables[key]) {
      nativeProps[key] = ConversionTables[key][value];
    } else {
      nativeProps[key] = value;
    }
  }
  return nativeProps;
}
function ensureNativeProps(props) {
  const newProps = convertNativeProps(props);
  if (newProps.onBarCodeScanned) {
    newProps.barCodeScannerEnabled = true;
  }
  if (newProps.onFacesDetected) {
    newProps.faceDetectorEnabled = true;
  }
  if (Platform_default.OS !== "android") {
    delete newProps.ratio;
    delete newProps.useCamera2Api;
  }
  if (Platform_default.OS !== "web") {
    delete newProps.poster;
  }
  return newProps;
}

// ../node_modules/expo-camera/build/Camera.js
var EventThrottleMs = 500;
var _PICTURE_SAVED_CALLBACKS = {};
var _GLOBAL_PICTURE_ID = 1;
function ensurePictureOptions(options) {
  const pictureOptions = !options || typeof options !== "object" ? {} : options;
  if (!pictureOptions.quality) {
    pictureOptions.quality = 1;
  }
  if (pictureOptions.onPictureSaved) {
    const id = _GLOBAL_PICTURE_ID++;
    _PICTURE_SAVED_CALLBACKS[id] = pictureOptions.onPictureSaved;
    pictureOptions.id = id;
    pictureOptions.fastMode = true;
  }
  return pictureOptions;
}
function ensureRecordingOptions(options) {
  let recordingOptions = options || {};
  if (!recordingOptions || typeof recordingOptions !== "object") {
    recordingOptions = {};
  } else if (typeof recordingOptions.quality === "string") {
    recordingOptions.quality = Camera.Constants.VideoQuality[recordingOptions.quality];
  }
  return recordingOptions;
}
function _onPictureSaved({ nativeEvent }) {
  const { id, data } = nativeEvent;
  const callback = _PICTURE_SAVED_CALLBACKS[id];
  if (callback) {
    callback(data);
    delete _PICTURE_SAVED_CALLBACKS[id];
  }
}
var _Camera = class _Camera extends React4.Component {
  constructor() {
    super(...arguments);
    __publicField(this, "_cameraHandle");
    __publicField(this, "_cameraRef");
    __publicField(this, "_lastEvents", {});
    __publicField(this, "_lastEventsTimes", {});
    __publicField(this, "_onCameraReady", () => {
      if (this.props.onCameraReady) {
        this.props.onCameraReady();
      }
    });
    __publicField(this, "_onMountError", ({ nativeEvent }) => {
      if (this.props.onMountError) {
        this.props.onMountError(nativeEvent);
      }
    });
    __publicField(this, "_onResponsiveOrientationChanged", ({ nativeEvent }) => {
      if (this.props.onResponsiveOrientationChanged) {
        this.props.onResponsiveOrientationChanged(nativeEvent);
      }
    });
    __publicField(this, "_onObjectDetected", (callback) => ({ nativeEvent }) => {
      const { type } = nativeEvent;
      if (this._lastEvents[type] && this._lastEventsTimes[type] && JSON.stringify(nativeEvent) === this._lastEvents[type] && (/* @__PURE__ */ new Date()).getTime() - this._lastEventsTimes[type].getTime() < EventThrottleMs) {
        return;
      }
      if (callback) {
        callback(nativeEvent);
        this._lastEventsTimes[type] = /* @__PURE__ */ new Date();
        this._lastEvents[type] = JSON.stringify(nativeEvent);
      }
    });
    __publicField(this, "_setReference", (ref) => {
      if (ref) {
        this._cameraRef = ref;
        if (Platform_default.OS === "web") {
          this._cameraHandle = ref;
        } else {
          this._cameraHandle = findNodeHandle_default(ref);
        }
      } else {
        this._cameraRef = null;
        this._cameraHandle = null;
      }
    });
  }
  /**
   * Check whether the current device has a camera. This is useful for web and simulators cases.
   * This isn't influenced by the Permissions API (all platforms), or HTTP usage (in the browser).
   * You will still need to check if the native permission has been accepted.
   * @platform web
   */
  static async isAvailableAsync() {
    if (!ExponentCameraManager_web_default.isAvailableAsync) {
      throw new UnavailabilityError("expo-camera", "isAvailableAsync");
    }
    return await ExponentCameraManager_web_default.isAvailableAsync();
  }
  /**
   * Returns a list of camera types `['front', 'back']`. This is useful for desktop browsers which only have front-facing cameras.
   * @platform web
   */
  static async getAvailableCameraTypesAsync() {
    if (!ExponentCameraManager_web_default.getAvailableCameraTypesAsync) {
      throw new UnavailabilityError("expo-camera", "getAvailableCameraTypesAsync");
    }
    return await ExponentCameraManager_web_default.getAvailableCameraTypesAsync();
  }
  // @needsAudit
  /**
   * Queries the device for the available video codecs that can be used in video recording.
   * @return A promise that resolves to a list of strings that represents available codecs.
   * @platform ios
   */
  static async getAvailableVideoCodecsAsync() {
    if (!ExponentCameraManager_web_default.getAvailableVideoCodecsAsync) {
      throw new UnavailabilityError("Camera", "getAvailableVideoCodecsAsync");
    }
    return await ExponentCameraManager_web_default.getAvailableVideoCodecsAsync();
  }
  // @needsAudit
  /**
   * @deprecated Use `getCameraPermissionsAsync` or `getMicrophonePermissionsAsync` instead.
   * Checks user's permissions for accessing camera.
   */
  static async getPermissionsAsync() {
    console.warn(`"getPermissionsAsync()" is now deprecated. Please use "getCameraPermissionsAsync()" or "getMicrophonePermissionsAsync()" instead.`);
    return ExponentCameraManager_web_default.getPermissionsAsync();
  }
  // @needsAudit
  /**
   * Asks the user to grant permissions for accessing camera.
   * On iOS this will require apps to specify both `NSCameraUsageDescription` and `NSMicrophoneUsageDescription` entries in the **Info.plist**.
   * @return A promise that resolves to an object of type [PermissionResponse](#permissionresponse).
   * @deprecated Use `requestCameraPermissionsAsync` or `requestMicrophonePermissionsAsync` instead.
   */
  static async requestPermissionsAsync() {
    console.warn(`"requestPermissionsAsync()" is now deprecated. Please use "requestCameraPermissionsAsync()" or "requestMicrophonePermissionsAsync()" instead.`);
    return ExponentCameraManager_web_default.requestPermissionsAsync();
  }
  // @needsAudit
  /**
   * Checks user's permissions for accessing camera.
   * @return A promise that resolves to an object of type [PermissionResponse](#permissionresponse).
   */
  static async getCameraPermissionsAsync() {
    return ExponentCameraManager_web_default.getCameraPermissionsAsync();
  }
  // @needsAudit
  /**
   * Asks the user to grant permissions for accessing camera.
   * On iOS this will require apps to specify an `NSCameraUsageDescription` entry in the **Info.plist**.
   * @return A promise that resolves to an object of type [PermissionResponse](#permissionresponse).
   */
  static async requestCameraPermissionsAsync() {
    return ExponentCameraManager_web_default.requestCameraPermissionsAsync();
  }
  // @needsAudit
  /**
   * Checks user's permissions for accessing microphone.
   * @return A promise that resolves to an object of type [PermissionResponse](#permissionresponse).
   */
  static async getMicrophonePermissionsAsync() {
    return ExponentCameraManager_web_default.getMicrophonePermissionsAsync();
  }
  // @needsAudit
  /**
   * Asks the user to grant permissions for accessing the microphone.
   * On iOS this will require apps to specify an `NSMicrophoneUsageDescription` entry in the **Info.plist**.
   * @return A promise that resolves to an object of type [PermissionResponse](#permissionresponse).
   */
  static async requestMicrophonePermissionsAsync() {
    return ExponentCameraManager_web_default.requestMicrophonePermissionsAsync();
  }
  // @needsAudit
  /**
   * Takes a picture and saves it to app's cache directory. Photos are rotated to match device's orientation
   * (if `options.skipProcessing` flag is not enabled) and scaled to match the preview. Anyway on Android it is essential
   * to set ratio prop to get a picture with correct dimensions.
   * > **Note**: Make sure to wait for the [`onCameraReady`](#oncameraready) callback before calling this method.
   * @param options An object in form of `CameraPictureOptions` type.
   * @return Returns a Promise that resolves to `CameraCapturedPicture` object, where `uri` is a URI to the local image file on iOS,
   * Android, and a base64 string on web (usable as the source for an `Image` element). The `width` and `height` properties specify
   * the dimensions of the image. `base64` is included if the `base64` option was truthy, and is a string containing the JPEG data
   * of the image in Base64--prepend that with `'data:image/jpg;base64,'` to get a data URI, which you can use as the source
   * for an `Image` element for example. `exif` is included if the `exif` option was truthy, and is an object containing EXIF
   * data for the image--the names of its properties are EXIF tags and their values are the values for those tags.
   *
   * > On native platforms, the local image URI is temporary. Use [`FileSystem.copyAsync`](filesystem.md#filesystemcopyasyncoptions)
   * > to make a permanent copy of the image.
   */
  async takePictureAsync(options) {
    const pictureOptions = ensurePictureOptions(options);
    return await ExponentCameraManager_web_default.takePicture(pictureOptions, this._cameraHandle);
  }
  /**
   * Get aspect ratios that are supported by the device and can be passed via `ratio` prop.
   * @return Returns a Promise that resolves to an array of strings representing ratios, eg. `['4:3', '1:1']`.
   * @platform android
   */
  async getSupportedRatiosAsync() {
    if (!ExponentCameraManager_web_default.getSupportedRatios) {
      throw new UnavailabilityError("Camera", "getSupportedRatiosAsync");
    }
    return await ExponentCameraManager_web_default.getSupportedRatios(this._cameraHandle);
  }
  /**
   * Get picture sizes that are supported by the device for given `ratio`.
   * @param ratio A string representing aspect ratio of sizes to be returned.
   * @return Returns a Promise that resolves to an array of strings representing picture sizes that can be passed to `pictureSize` prop.
   * The list varies across Android devices but is the same for every iOS.
   */
  async getAvailablePictureSizesAsync(ratio) {
    if (!ExponentCameraManager_web_default.getAvailablePictureSizes) {
      throw new UnavailabilityError("Camera", "getAvailablePictureSizesAsync");
    }
    return await ExponentCameraManager_web_default.getAvailablePictureSizes(ratio, this._cameraHandle);
  }
  /**
   * Starts recording a video that will be saved to cache directory. Videos are rotated to match device's orientation.
   * Flipping camera during a recording results in stopping it.
   * @param options A map of `CameraRecordingOptions` type.
   * @return Returns a Promise that resolves to an object containing video file `uri` property and a `codec` property on iOS.
   * The Promise is returned if `stopRecording` was invoked, one of `maxDuration` and `maxFileSize` is reached or camera preview is stopped.
   * @platform android
   * @platform ios
   */
  async recordAsync(options) {
    if (!ExponentCameraManager_web_default.record) {
      throw new UnavailabilityError("Camera", "recordAsync");
    }
    const recordingOptions = ensureRecordingOptions(options);
    return await ExponentCameraManager_web_default.record(recordingOptions, this._cameraHandle);
  }
  /**
   * Stops recording if any is in progress.
   */
  stopRecording() {
    if (!ExponentCameraManager_web_default.stopRecording) {
      throw new UnavailabilityError("Camera", "stopRecording");
    }
    ExponentCameraManager_web_default.stopRecording(this._cameraHandle);
  }
  /**
   * Pauses the camera preview. It is not recommended to use `takePictureAsync` when preview is paused.
   */
  pausePreview() {
    if (!ExponentCameraManager_web_default.pausePreview) {
      throw new UnavailabilityError("Camera", "pausePreview");
    }
    ExponentCameraManager_web_default.pausePreview(this._cameraHandle);
  }
  /**
   * Resumes the camera preview.
   */
  resumePreview() {
    if (!ExponentCameraManager_web_default.resumePreview) {
      throw new UnavailabilityError("Camera", "resumePreview");
    }
    ExponentCameraManager_web_default.resumePreview(this._cameraHandle);
  }
  render() {
    const nativeProps = ensureNativeProps(this.props);
    const onBarCodeScanned = this.props.onBarCodeScanned ? this._onObjectDetected(this.props.onBarCodeScanned) : void 0;
    const onFacesDetected = this._onObjectDetected(this.props.onFacesDetected);
    return React4.createElement(ExponentCamera_web_default, { ...nativeProps, ref: this._setReference, onCameraReady: this._onCameraReady, onMountError: this._onMountError, onBarCodeScanned, onFacesDetected, onPictureSaved: _onPictureSaved, onResponsiveOrientationChanged: this._onResponsiveOrientationChanged });
  }
};
__publicField(_Camera, "Constants", {
  Type: ExponentCameraManager_web_default.Type,
  FlashMode: ExponentCameraManager_web_default.FlashMode,
  AutoFocus: ExponentCameraManager_web_default.AutoFocus,
  WhiteBalance: ExponentCameraManager_web_default.WhiteBalance,
  VideoQuality: ExponentCameraManager_web_default.VideoQuality,
  VideoStabilization: ExponentCameraManager_web_default.VideoStabilization || {},
  VideoCodec: ExponentCameraManager_web_default.VideoCodec
});
// Values under keys from this object will be transformed to native options
__publicField(_Camera, "ConversionTables", ConversionTables);
__publicField(_Camera, "defaultProps", {
  zoom: 0,
  ratio: "4:3",
  focusDepth: 0,
  faceDetectorSettings: {},
  type: ExponentCameraManager_web_default.Type.back,
  autoFocus: ExponentCameraManager_web_default.AutoFocus.on,
  flashMode: ExponentCameraManager_web_default.FlashMode.off,
  whiteBalance: ExponentCameraManager_web_default.WhiteBalance.auto
});
// @needsAudit
/**
 * Check or request permissions to access the camera.
 * This uses both `requestCameraPermissionsAsync` and `getCameraPermissionsAsync` to interact with the permissions.
 *
 * @example
 * ```ts
 * const [status, requestPermission] = Camera.useCameraPermissions();
 * ```
 */
__publicField(_Camera, "useCameraPermissions", createPermissionHook({
  getMethod: _Camera.getCameraPermissionsAsync,
  requestMethod: _Camera.requestCameraPermissionsAsync
}));
// @needsAudit
/**
 * Check or request permissions to access the microphone.
 * This uses both `requestMicrophonePermissionsAsync` and `getMicrophonePermissionsAsync` to interact with the permissions.
 *
 * @example
 * ```ts
 * const [status, requestPermission] = Camera.useMicrophonePermissions();
 * ```
 */
__publicField(_Camera, "useMicrophonePermissions", createPermissionHook({
  getMethod: _Camera.getMicrophonePermissionsAsync,
  requestMethod: _Camera.requestMicrophonePermissionsAsync
}));
var Camera = _Camera;
var { Constants, getPermissionsAsync, requestPermissionsAsync, getCameraPermissionsAsync, requestCameraPermissionsAsync, getMicrophonePermissionsAsync, requestMicrophonePermissionsAsync } = Camera;
export {
  AutoFocus,
  Camera,
  CameraOrientation,
  CameraType,
  Constants,
  FlashMode,
  ImageType,
  PermissionStatus,
  VideoCodec,
  VideoQuality,
  VideoStabilization,
  WhiteBalance,
  getCameraPermissionsAsync,
  getMicrophonePermissionsAsync,
  getPermissionsAsync,
  requestCameraPermissionsAsync,
  requestMicrophonePermissionsAsync,
  requestPermissionsAsync
};
//# sourceMappingURL=expo-camera.js.map
